{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fine-tuning Aya Vision 8B for African Languages\n",
    "\n",
    "This notebook demonstrates how to fine-tune the Aya Vision 8B model using LoRA (Low-Rank Adaptation) for improved performance on African language vision-language tasks.\n",
    "\n",
    "## Model Overview\n",
    "- **Model**: CohereLabs/aya-vision-8b\n",
    "- **Parameters**: 8 billion\n",
    "- **Context Length**: 16K tokens\n",
    "- **Languages**: 23 languages including African languages\n",
    "- **Architecture**: Vision-Language Model with SigLIP2 vision encoder\n",
    "\n",
    "## Key Features of This Notebook\n",
    "- Memory-efficient training with 4-bit quantization\n",
    "- LoRA fine-tuning for reduced computational requirements\n",
    "- Automatic model saving and uploading to Hugging Face\n",
    "- Progress tracking and checkpoint saving\n",
    "- Support for custom African language datasets\n",
    "\n",
    "## Requirements\n",
    "- Kaggle GPU environment (T4 or P100 recommended)\n",
    "- Hugging Face account with write token\n",
    "- Dataset uploaded to Hugging Face Hub\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üìã Phase 1: Environment Setup and Installation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install required libraries\n",
    "!pip install -q \"transformers==4.49.0\" \"datasets==2.19.1\" \"accelerate==0.30.1\" \n",
    "!pip install -q \"bitsandbytes==0.43.1\" \"peft==0.11.1\" \"trl==0.9.4\"\n",
    "!pip install -q \"torch>=2.0.0\" \"torchvision\" \"pillow\" \"wandb\"\n",
    "\n",
    "print(\"‚úÖ All packages installed successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import os\n",
    "import torch\n",
    "import json\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Core ML libraries\n",
    "from transformers import (\n",
    "    AutoProcessor, \n",
    "    AutoModelForImageTextToText, \n",
    "    BitsAndBytesConfig,\n",
    "    TrainingArguments\n",
    ")\n",
    "from peft import LoraConfig, get_peft_model, TaskType\n",
    "from trl import SFTTrainer, SFTConfig\n",
    "from datasets import load_dataset, Dataset\n",
    "from huggingface_hub import notebook_login, HfApi\n",
    "\n",
    "print(f\"‚úÖ PyTorch version: {torch.__version__}\")\n",
    "print(f\"‚úÖ CUDA available: {torch.cuda.is_available()}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"‚úÖ GPU: {torch.cuda.get_device_name(0)}\")\n",
    "    print(f\"‚úÖ GPU Memory: {torch.cuda.get_device_properties(0).total_memory / 1e9:.1f} GB\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üîê Phase 2: Authentication and Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuration parameters\n",
    "CONFIG = {\n",
    "    # Model settings\n",
    "    \"base_model_id\": \"CohereLabs/aya-vision-8b\",\n",
    "    \"new_model_name\": \"aya-vision-8b-african-finetuned\",  # Change this to your desired name\n",
    "    \"hub_model_id\": None,  # Will be set after login\n",
    "    \n",
    "    # Dataset settings\n",
    "    \"dataset_id\": \"Afri-Aya/afri-aya-dataset-v1\",  # Replace with your dataset\n",
    "    \"dataset_split\": \"train\",\n",
    "    \"max_samples\": None,  # Set to a number for testing, None for full dataset\n",
    "    \n",
    "    # Training settings\n",
    "    \"num_epochs\": 1,\n",
    "    \"batch_size\": 2,\n",
    "    \"gradient_accumulation_steps\": 8,\n",
    "    \"learning_rate\": 2e-4,\n",
    "    \"max_seq_length\": 1024,\n",
    "    \"save_steps\": 50,\n",
    "    \"logging_steps\": 10,\n",
    "    \n",
    "    # LoRA settings\n",
    "    \"lora_r\": 16,\n",
    "    \"lora_alpha\": 32,\n",
    "    \"lora_dropout\": 0.05,\n",
    "    \n",
    "    # Other settings\n",
    "    \"temperature\": 0.3,\n",
    "    \"max_new_tokens\": 300,\n",
    "}\n",
    "\n",
    "print(\"üìã Configuration loaded:\")\n",
    "for key, value in CONFIG.items():\n",
    "    print(f\"  {key}: {value}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Login to Hugging Face\n",
    "try:\n",
    "    notebook_login()\n",
    "    \n",
    "    # Get username for model naming\n",
    "    api = HfApi()\n",
    "    username = api.whoami()[\"name\"]\n",
    "    CONFIG[\"hub_model_id\"] = f\"{username}/{CONFIG['new_model_name']}\"\n",
    "    \n",
    "    print(f\"‚úÖ Logged in as: {username}\")\n",
    "    print(f\"üéØ Model will be saved as: {CONFIG['hub_model_id']}\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Login failed: {e}\")\n",
    "    print(\"Please ensure your HF_TOKEN is properly set in Kaggle secrets\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üìä Phase 3: Data Loading and Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load dataset\n",
    "print(f\"üì• Loading dataset: {CONFIG['dataset_id']}\")\n",
    "\n",
    "try:\n",
    "    dataset = load_dataset(CONFIG[\"dataset_id\"], split=CONFIG[\"dataset_split\"])\n",
    "    print(f\"‚úÖ Dataset loaded successfully!\")\n",
    "    print(f\"üìä Dataset size: {len(dataset)} samples\")\n",
    "    \n",
    "    # Show dataset structure\n",
    "    print(\"\\nüìã Dataset columns:\", dataset.column_names)\n",
    "    print(\"\\nüîç Sample entry:\")\n",
    "    sample = dataset[0]\n",
    "    for key, value in sample.items():\n",
    "        if key == 'image':\n",
    "            print(f\"  {key}: <PIL.Image object>\")\n",
    "        else:\n",
    "            print(f\"  {key}: {str(value)[:100]}...\" if len(str(value)) > 100 else f\"  {key}: {value}\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Failed to load dataset: {e}\")\n",
    "    print(\"Please check your dataset ID and ensure it's publicly accessible\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optional: Create a smaller subset for testing\n",
    "if CONFIG[\"max_samples\"] is not None:\n",
    "    print(f\"üîÑ Creating subset of {CONFIG['max_samples']} samples for testing...\")\n",
    "    dataset = dataset.shuffle(seed=42).select(range(min(CONFIG[\"max_samples\"], len(dataset))))\n",
    "    print(f\"‚úÖ Subset created with {len(dataset)} samples\")\n",
    "\n",
    "print(f\"\\nüìä Final dataset size: {len(dataset)} samples\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data formatting function for Aya Vision chat template\n",
    "def format_for_aya_vision(example):\n",
    "    \"\"\"\n",
    "    Format dataset entries for Aya Vision chat template.\n",
    "    Adjust this function based on your dataset structure.\n",
    "    \"\"\"\n",
    "    # Example assumes your dataset has 'image' and 'caption' or similar fields\n",
    "    # Modify these field names based on your actual dataset structure\n",
    "    \n",
    "    # Default prompts - customize based on your use case\n",
    "    prompts = [\n",
    "        \"Describe this image in detail.\",\n",
    "        \"What do you see in this image?\",\n",
    "        \"Please provide a detailed caption for this image.\",\n",
    "        \"What is happening in this image?\"\n",
    "    ]\n",
    "    \n",
    "    # Use different fields based on your dataset structure\n",
    "    if \"english_caption\" in example:\n",
    "        response = example[\"english_caption\"]\n",
    "    elif \"caption\" in example:\n",
    "        response = example[\"caption\"]\n",
    "    elif \"description\" in example:\n",
    "        response = example[\"description\"]\n",
    "    else:\n",
    "        # Try to find any text field\n",
    "        text_fields = [k for k, v in example.items() if isinstance(v, str) and len(v) > 10]\n",
    "        response = example[text_fields[0]] if text_fields else \"This is an image.\"\n",
    "    \n",
    "    # Select a random prompt or use the first one\n",
    "    import random\n",
    "    user_prompt = random.choice(prompts)\n",
    "    \n",
    "    return {\n",
    "        \"image\": example[\"image\"],\n",
    "        \"messages\": [\n",
    "            {\n",
    "                \"role\": \"user\", \n",
    "                \"content\": f\"<image>\\n{user_prompt}\"\n",
    "            },\n",
    "            {\n",
    "                \"role\": \"assistant\", \n",
    "                \"content\": response\n",
    "            }\n",
    "        ]\n",
    "    }\n",
    "\n",
    "# Format the dataset\n",
    "print(\"üîÑ Formatting dataset for training...\")\n",
    "formatted_dataset = dataset.map(format_for_aya_vision, desc=\"Formatting data\")\n",
    "\n",
    "print(\"‚úÖ Dataset formatted successfully!\")\n",
    "print(\"\\nüîç Sample formatted entry:\")\n",
    "sample_formatted = formatted_dataset[0]\n",
    "print(f\"Messages: {sample_formatted['messages']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ü§ñ Phase 4: Model and Processor Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configure 4-bit quantization for memory efficiency\n",
    "bnb_config = BitsAndBytesConfig(\n",
    "    load_in_4bit=True,\n",
    "    bnb_4bit_quant_type=\"nf4\",\n",
    "    bnb_4bit_compute_dtype=torch.bfloat16,\n",
    "    bnb_4bit_use_double_quant=True\n",
    ")\n",
    "\n",
    "print(\"‚öôÔ∏è Quantization config created\")\n",
    "print(f\"  Quantization type: 4-bit NF4\")\n",
    "print(f\"  Compute dtype: {bnb_config.bnb_4bit_compute_dtype}\")\n",
    "print(f\"  Double quantization: {bnb_config.bnb_4bit_use_double_quant}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load processor first\n",
    "print(f\"üì• Loading processor for {CONFIG['base_model_id']}...\")\n",
    "\n",
    "try:\n",
    "    processor = AutoProcessor.from_pretrained(\n",
    "        CONFIG[\"base_model_id\"], \n",
    "        trust_remote_code=True\n",
    "    )\n",
    "    print(\"‚úÖ Processor loaded successfully!\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Failed to load processor: {e}\")\n",
    "    raise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the base model with quantization\n",
    "print(f\"üì• Loading model {CONFIG['base_model_id']} with 4-bit quantization...\")\n",
    "print(\"‚è≥ This may take several minutes...\")\n",
    "\n",
    "try:\n",
    "    model = AutoModelForImageTextToText.from_pretrained(\n",
    "        CONFIG[\"base_model_id\"],\n",
    "        quantization_config=bnb_config,\n",
    "        device_map=\"auto\",\n",
    "        trust_remote_code=True,\n",
    "        torch_dtype=torch.bfloat16\n",
    "    )\n",
    "    \n",
    "    print(\"‚úÖ Model loaded successfully!\")\n",
    "    print(f\"üéØ Model device: {next(model.parameters()).device}\")\n",
    "    print(f\"üìä Model dtype: {next(model.parameters()).dtype}\")\n",
    "    \n",
    "    # Display memory usage\n",
    "    if torch.cuda.is_available():\n",
    "        memory_used = torch.cuda.memory_allocated() / 1e9\n",
    "        memory_total = torch.cuda.get_device_properties(0).total_memory / 1e9\n",
    "        print(f\"üíæ GPU Memory used: {memory_used:.1f} GB / {memory_total:.1f} GB\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Failed to load model: {e}\")\n",
    "    raise"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üîß Phase 5: LoRA Configuration and Model Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configure LoRA for efficient fine-tuning\n",
    "lora_config = LoraConfig(\n",
    "    r=CONFIG[\"lora_r\"],\n",
    "    lora_alpha=CONFIG[\"lora_alpha\"],\n",
    "    lora_dropout=CONFIG[\"lora_dropout\"],\n",
    "    bias=\"none\",\n",
    "    target_modules=[\"q_proj\", \"k_proj\", \"v_proj\", \"o_proj\"],  # Standard attention modules\n",
    "    task_type=TaskType.CAUSAL_LM\n",
    ")\n",
    "\n",
    "print(\"üîß LoRA configuration:\")\n",
    "print(f\"  Rank (r): {lora_config.r}\")\n",
    "print(f\"  Alpha: {lora_config.lora_alpha}\")\n",
    "print(f\"  Dropout: {lora_config.lora_dropout}\")\n",
    "print(f\"  Target modules: {lora_config.target_modules}\")\n",
    "\n",
    "# Calculate trainable parameters\n",
    "def count_parameters(model):\n",
    "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "\n",
    "trainable_params_before = count_parameters(model)\n",
    "print(f\"\\nüìä Trainable parameters before LoRA: {trainable_params_before:,}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply LoRA to the model\n",
    "print(\"üîÑ Applying LoRA adapters to the model...\")\n",
    "\n",
    "try:\n",
    "    model = get_peft_model(model, lora_config)\n",
    "    \n",
    "    # Print trainable parameters info\n",
    "    model.print_trainable_parameters()\n",
    "    \n",
    "    trainable_params_after = count_parameters(model)\n",
    "    total_params = sum(p.numel() for p in model.parameters())\n",
    "    \n",
    "    print(f\"\\nüìä Parameter Statistics:\")\n",
    "    print(f\"  Total parameters: {total_params:,}\")\n",
    "    print(f\"  Trainable parameters: {trainable_params_after:,}\")\n",
    "    print(f\"  Trainable %: {100 * trainable_params_after / total_params:.2f}%\")\n",
    "    print(f\"  Parameter reduction: {trainable_params_before / trainable_params_after:.1f}x\")\n",
    "    \n",
    "    print(\"‚úÖ LoRA adapters applied successfully!\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Failed to apply LoRA: {e}\")\n",
    "    raise"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üèÉ‚Äç‚ôÇÔ∏è Phase 6: Training Configuration and Execution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup training arguments\n",
    "training_args = SFTConfig(\n",
    "    output_dir=CONFIG[\"new_model_name\"],\n",
    "    num_train_epochs=CONFIG[\"num_epochs\"],\n",
    "    per_device_train_batch_size=CONFIG[\"batch_size\"],\n",
    "    gradient_accumulation_steps=CONFIG[\"gradient_accumulation_steps\"],\n",
    "    learning_rate=CONFIG[\"learning_rate\"],\n",
    "    logging_steps=CONFIG[\"logging_steps\"],\n",
    "    save_strategy=\"steps\",\n",
    "    save_steps=CONFIG[\"save_steps\"],\n",
    "    eval_strategy=\"no\",  # Can be changed to \"steps\" if you have eval data\n",
    "    push_to_hub=True,\n",
    "    hub_model_id=CONFIG[\"hub_model_id\"],\n",
    "    report_to=\"tensorboard\",\n",
    "    fp16=False,  # Using bfloat16 instead\n",
    "    bf16=True,\n",
    "    max_seq_length=CONFIG[\"max_seq_length\"],\n",
    "    dataloader_num_workers=2,\n",
    "    remove_unused_columns=False,\n",
    "    gradient_checkpointing=True,\n",
    "    warmup_ratio=0.1,\n",
    "    weight_decay=0.01,\n",
    "    optim=\"paged_adamw_8bit\",  # Memory efficient optimizer\n",
    ")\n",
    "\n",
    "print(\"üìã Training Configuration:\")\n",
    "print(f\"  Epochs: {training_args.num_train_epochs}\")\n",
    "print(f\"  Batch size: {training_args.per_device_train_batch_size}\")\n",
    "print(f\"  Gradient accumulation: {training_args.gradient_accumulation_steps}\")\n",
    "print(f\"  Effective batch size: {training_args.per_device_train_batch_size * training_args.gradient_accumulation_steps}\")\n",
    "print(f\"  Learning rate: {training_args.learning_rate}\")\n",
    "print(f\"  Max sequence length: {training_args.max_seq_length}\")\n",
    "print(f\"  Output directory: {training_args.output_dir}\")\n",
    "print(f\"  Hub model ID: {training_args.hub_model_id}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the SFT Trainer\n",
    "print(\"üèóÔ∏è Initializing SFT Trainer...\")\n",
    "\n",
    "try:\n",
    "    trainer = SFTTrainer(\n",
    "        model=model,\n",
    "        args=training_args,\n",
    "        train_dataset=formatted_dataset,\n",
    "        processor=processor,\n",
    "        peft_config=lora_config,\n",
    "    )\n",
    "    \n",
    "    print(\"‚úÖ Trainer initialized successfully!\")\n",
    "    print(f\"üìä Training dataset size: {len(formatted_dataset)}\")\n",
    "    \n",
    "    # Calculate training steps\n",
    "    total_steps = len(formatted_dataset) // (training_args.per_device_train_batch_size * training_args.gradient_accumulation_steps) * training_args.num_train_epochs\n",
    "    print(f\"üìà Estimated total training steps: {total_steps}\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Failed to initialize trainer: {e}\")\n",
    "    raise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start training\n",
    "print(\"üöÄ Starting training...\")\n",
    "print(f\"‚è∞ Training started at: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\")\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"üî• TRAINING IN PROGRESS\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "try:\n",
    "    # Start training\n",
    "    training_output = trainer.train()\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*50)\n",
    "    print(\"‚úÖ TRAINING COMPLETED SUCCESSFULLY!\")\n",
    "    print(\"=\"*50)\n",
    "    print(f\"‚è∞ Training finished at: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\")\n",
    "    \n",
    "    # Print training metrics\n",
    "    if hasattr(training_output, 'metrics'):\n",
    "        print(\"\\nüìä Final Training Metrics:\")\n",
    "        for key, value in training_output.metrics.items():\n",
    "            print(f\"  {key}: {value}\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"\\n‚ùå Training failed: {e}\")\n",
    "    print(\"üí° Check the error message above and consider reducing batch size or sequence length\")\n",
    "    raise"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üíæ Phase 7: Model Saving and Upload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the final model\n",
    "print(\"üíæ Saving the fine-tuned model...\")\n",
    "\n",
    "try:\n",
    "    # Save model locally first\n",
    "    trainer.save_model()\n",
    "    print(f\"‚úÖ Model saved locally to: {training_args.output_dir}\")\n",
    "    \n",
    "    # Save processor as well\n",
    "    processor.save_pretrained(training_args.output_dir)\n",
    "    print(\"‚úÖ Processor saved locally\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Failed to save model locally: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Push to Hugging Face Hub\n",
    "print(f\"üöÄ Uploading model to Hugging Face Hub: {CONFIG['hub_model_id']}\")\n",
    "\n",
    "try:\n",
    "    # Push the model\n",
    "    trainer.push_to_hub()\n",
    "    print(f\"‚úÖ Model uploaded successfully to: https://huggingface.co/{CONFIG['hub_model_id']}\")\n",
    "    \n",
    "    # Create and upload model card\n",
    "    model_card_content = f\"\"\"\n",
    "# {CONFIG['new_model_name']}\n",
    "\n",
    "This model is a fine-tuned version of [{CONFIG['base_model_id']}](https://huggingface.co/{CONFIG['base_model_id']}) \n",
    "for improved performance on African language vision-language tasks.\n",
    "\n",
    "## Training Details\n",
    "\n",
    "- **Base Model**: {CONFIG['base_model_id']}\n",
    "- **Fine-tuning Method**: LoRA (Low-Rank Adaptation)\n",
    "- **Training Data**: {CONFIG['dataset_id']}\n",
    "- **Training Samples**: {len(formatted_dataset)}\n",
    "- **Epochs**: {CONFIG['num_epochs']}\n",
    "- **Batch Size**: {CONFIG['batch_size']}\n",
    "- **Learning Rate**: {CONFIG['learning_rate']}\n",
    "- **LoRA Rank**: {CONFIG['lora_r']}\n",
    "- **LoRA Alpha**: {CONFIG['lora_alpha']}\n",
    "\n",
    "## Usage\n",
    "\n",
    "```python\n",
    "from transformers import AutoProcessor, AutoModelForImageTextToText\n",
    "from peft import PeftModel\n",
    "\n",
    "# Load the base model and processor\n",
    "base_model = AutoModelForImageTextToText.from_pretrained(\"{CONFIG['base_model_id']}\")\n",
    "processor = AutoProcessor.from_pretrained(\"{CONFIG['base_model_id']}\")\n",
    "\n",
    "# Load the fine-tuned LoRA weights\n",
    "model = PeftModel.from_pretrained(base_model, \"{CONFIG['hub_model_id']}\")\n",
    "\n",
    "# Use the model for inference\n",
    "# [Add your inference code here]\n",
    "```\n",
    "\n",
    "## Training Infrastructure\n",
    "\n",
    "- **Platform**: Kaggle\n",
    "- **GPU**: {torch.cuda.get_device_name(0) if torch.cuda.is_available() else 'CPU'}\n",
    "- **Training Date**: {datetime.now().strftime('%Y-%m-%d')}\n",
    "\n",
    "## African Language Support\n",
    "\n",
    "This model has been fine-tuned to better understand and generate content related to African languages and cultures,\n",
    "building upon the strong multilingual foundation of the base Aya Vision model.\n",
    "\"\"\"\n",
    "    \n",
    "    # Save model card\n",
    "    with open(os.path.join(training_args.output_dir, \"README.md\"), \"w\") as f:\n",
    "        f.write(model_card_content)\n",
    "    \n",
    "    print(\"‚úÖ Model card created and uploaded\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Failed to upload to Hub: {e}\")\n",
    "    print(\"üí° You can manually upload later using: trainer.push_to_hub()\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üß™ Phase 8: Model Testing and Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test the fine-tuned model\n",
    "print(\"üß™ Testing the fine-tuned model...\")\n",
    "\n",
    "# Get a test sample from the dataset\n",
    "test_sample = formatted_dataset[0]\n",
    "test_image = test_sample[\"image\"]\n",
    "test_messages = test_sample[\"messages\"]\n",
    "\n",
    "print(\"üì∏ Test image loaded\")\n",
    "print(f\"üí¨ Test prompt: {test_messages[0]['content']}\")\n",
    "print(f\"üéØ Expected response: {test_messages[1]['content'][:200]}...\")\n",
    "\n",
    "# Prepare the input\n",
    "test_messages_for_inference = [{\n",
    "    \"role\": \"user\",\n",
    "    \"content\": [\n",
    "        {\"type\": \"image\", \"url\": test_image},\n",
    "        {\"type\": \"text\", \"text\": \"Describe this image in detail.\"}\n",
    "    ]\n",
    "}]\n",
    "\n",
    "try:\n",
    "    # Apply chat template\n",
    "    inputs = processor.apply_chat_template(\n",
    "        test_messages_for_inference,\n",
    "        padding=True,\n",
    "        add_generation_prompt=True,\n",
    "        tokenize=True,\n",
    "        return_dict=True,\n",
    "        return_tensors=\"pt\"\n",
    "    ).to(model.device)\n",
    "    \n",
    "    # Generate response\n",
    "    print(\"\\nüîÑ Generating response...\")\n",
    "    with torch.no_grad():\n",
    "        gen_tokens = model.generate(\n",
    "            **inputs,\n",
    "            max_new_tokens=CONFIG[\"max_new_tokens\"],\n",
    "            do_sample=True,\n",
    "            temperature=CONFIG[\"temperature\"],\n",
    "            pad_token_id=processor.tokenizer.eos_token_id\n",
    "        )\n",
    "    \n",
    "    # Decode the response\n",
    "    response = processor.tokenizer.decode(\n",
    "        gen_tokens[0][inputs.input_ids.shape[1]:], \n",
    "        skip_special_tokens=True\n",
    "    )\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*50)\n",
    "    print(\"ü§ñ MODEL RESPONSE:\")\n",
    "    print(\"=\"*50)\n",
    "    print(response)\n",
    "    print(\"=\"*50)\n",
    "    \n",
    "    print(\"\\n‚úÖ Model test completed successfully!\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Model testing failed: {e}\")\n",
    "    print(\"üí° The model was trained but there might be an issue with inference\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üìà Phase 9: Training Summary and Next Steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print comprehensive training summary\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"üìä TRAINING SUMMARY\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "print(f\"\\nüéØ Model Information:\")\n",
    "print(f\"  Base Model: {CONFIG['base_model_id']}\")\n",
    "print(f\"  Fine-tuned Model: {CONFIG['hub_model_id']}\")\n",
    "print(f\"  Model Size: 8B parameters\")\n",
    "print(f\"  Fine-tuning Method: LoRA\")\n",
    "\n",
    "print(f\"\\nüìä Training Configuration:\")\n",
    "print(f\"  Dataset: {CONFIG['dataset_id']}\")\n",
    "print(f\"  Training Samples: {len(formatted_dataset):,}\")\n",
    "print(f\"  Epochs: {CONFIG['num_epochs']}\")\n",
    "print(f\"  Batch Size: {CONFIG['batch_size']}\")\n",
    "print(f\"  Gradient Accumulation: {CONFIG['gradient_accumulation_steps']}\")\n",
    "print(f\"  Learning Rate: {CONFIG['learning_rate']}\")\n",
    "print(f\"  LoRA Rank: {CONFIG['lora_r']}\")\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    final_memory = torch.cuda.memory_allocated() / 1e9\n",
    "    max_memory = torch.cuda.max_memory_allocated() / 1e9\n",
    "    total_memory = torch.cuda.get_device_properties(0).total_memory / 1e9\n",
    "    print(f\"\\nüíæ Memory Usage:\")\n",
    "    print(f\"  Current GPU Memory: {final_memory:.1f} GB\")\n",
    "    print(f\"  Peak GPU Memory: {max_memory:.1f} GB\")\n",
    "    print(f\"  Total GPU Memory: {total_memory:.1f} GB\")\n",
    "    print(f\"  Memory Efficiency: {max_memory/total_memory*100:.1f}%\")\n",
    "\n",
    "print(f\"\\nüöÄ Model Deployment:\")\n",
    "print(f\"  Hugging Face Hub: https://huggingface.co/{CONFIG['hub_model_id']}\")\n",
    "print(f\"  Local Save Path: {training_args.output_dir}\")\n",
    "\n",
    "print(f\"\\n‚è∞ Timing:\")\n",
    "print(f\"  Training Completed: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"üéâ FINE-TUNING COMPLETED SUCCESSFULLY!\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "print(\"\\nüî• Next Steps:\")\n",
    "print(\"  1. Test your model with different images and prompts\")\n",
    "print(\"  2. Evaluate on your specific use cases\")\n",
    "print(\"  3. Consider additional fine-tuning with more epochs if needed\")\n",
    "print(\"  4. Deploy your model for inference\")\n",
    "print(\"  5. Share your results with the community!\")\n",
    "\n",
    "print(f\"\\nüìö Resources:\")\n",
    "print(f\"  - Model Hub: https://huggingface.co/{CONFIG['hub_model_id']}\")\n",
    "print(f\"  - Base Model: https://huggingface.co/{CONFIG['base_model_id']}\")\n",
    "print(f\"  - Dataset: https://huggingface.co/datasets/{CONFIG['dataset_id']}\")\n",
    "print(f\"  - Aya Vision Paper: https://arxiv.org/abs/2412.04261\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üîß Troubleshooting and Tips\n",
    "\n",
    "### Common Issues and Solutions:\n",
    "\n",
    "1. **Out of Memory (OOM) Errors:**\n",
    "   - Reduce `batch_size` from 2 to 1\n",
    "   - Increase `gradient_accumulation_steps` to maintain effective batch size\n",
    "   - Reduce `max_seq_length` from 1024 to 512\n",
    "   - Use `torch.cuda.empty_cache()` between training phases\n",
    "\n",
    "2. **Training Too Slow:**\n",
    "   - Ensure you're using GPU T4 or P100 in Kaggle\n",
    "   - Enable `gradient_checkpointing=True` (already enabled)\n",
    "   - Use `dataloader_num_workers=0` if you have issues\n",
    "\n",
    "3. **Model Not Uploading to Hub:**\n",
    "   - Check your HF_TOKEN in Kaggle secrets\n",
    "   - Ensure you have write permissions\n",
    "   - Try manual upload: `trainer.push_to_hub()`\n",
    "\n",
    "4. **Dataset Loading Issues:**\n",
    "   - Ensure your dataset is public or you have access\n",
    "   - Check dataset structure matches expected format\n",
    "   - Modify the `format_for_aya_vision` function as needed\n",
    "\n",
    "### Performance Optimization Tips:\n",
    "\n",
    "- **For better quality:** Increase epochs to 2-3, but watch for overfitting\n",
    "- **For faster training:** Use smaller LoRA rank (r=8) and reduce max_seq_length\n",
    "- **For memory efficiency:** Use gradient_accumulation_steps=16 with batch_size=1\n",
    "- **For stability:** Keep learning_rate between 1e-4 and 5e-4\n",
    "\n",
    "### Kaggle-Specific Tips:\n",
    "\n",
    "- Save checkpoints frequently (every 50 steps) due to session limits\n",
    "- Monitor your GPU quota usage\n",
    "- Download important checkpoints before session expires\n",
    "- Use persistent storage for large datasets\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}